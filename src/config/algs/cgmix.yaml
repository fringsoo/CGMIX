# --- CGMIX parameters ---
name: "cgmix"

# use epsilon greedy action selector
action_selector: "epsilon_greedy"
epsilon_start: 1.0            # Initial epsilon for exploration
epsilon_finish: 0.05          # Final epsilon for exploration
epsilon_anneal_time: 50000    # Number of time steps until exploration has finished

# specify runner
buffer_size: 500              # Number of episodes in the experience replay buffer

# Specify the CG
cg_utilities_hidden_dim:      # Hidden layers of utility functions, by default None
cg_payoffs_hidden_dim:        # Hidden layers of payoff functions, by default None
msg_anytime: True             # Anytime extension of greedy action selection (Kok and Vlassis, 2006)
msg_iterations: 4             # Number of message passes in greedy action selection
msg_normalized: True          # Message normalization during greedy action selection (Kok and Vlassis, 2006)

# specify learner, controller and agent
agent: "rnn_feat"             # A RNN agent that returns its hidden state instead of its value
agent_output_type: "q"        # The output format is Q-values
learner: "cgmix_learner"        # The learner for Cgmix
mac: "cgmix_mac"                # The multi-agent controller for Cgmix
target_update_interval: 200   # Update the target network every {} episodes


mixer: "qmix"                 # QMIX
mixing_embed_dim: 2           # Hidden dimensions of the state dependent bias function of CGMIX
hypernet_layers: 2
hypernet_embed: 64